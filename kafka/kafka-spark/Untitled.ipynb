{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74e51965-526a-4c7b-b9cd-a99d1c7183bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "685ef691-8536-4f5e-9405-c626ca14fe1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/khanhpluto/khanhtv/test_spark/zxc/venv/lib/python3.6/site-packages/pyspark/context.py:238: FutureWarning: Python 3.6 support is deprecated in Spark 3.2.\n",
      "  FutureWarning\n"
     ]
    }
   ],
   "source": [
    "sc = pyspark.SparkContext(appName=\"maps_and_lazy_evaluation_example\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e39226b-35ca-4ada-9dd3-14bb196e51b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pi is roughly 4.000000\n"
     ]
    }
   ],
   "source": [
    "NUM_SAMPLES = 10\n",
    "\n",
    "def inside(p):\n",
    "    x, y = random.random(), random.random()\n",
    "    return x*x + y*y < 1\n",
    "\n",
    "count = sc.parallelize(range(0, NUM_SAMPLES)) \\\n",
    "             .filter(inside).count()\n",
    "print(\"Pi is roughly %f\" % (4.0 * count / NUM_SAMPLES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b510aa5a-b73e-49e0-bef4-1d1cc53187f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in text file and split each document into words\n",
    "words = sc.textFile(\"input.txt\").flatMap(lambda line: line.split(\" \"))\n",
    "\n",
    "# count the occurrence of each word\n",
    "wordCounts = words.map(lambda word: (word, 1)).reduceByKey(lambda a,b:a +b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82f8c5c8-902b-4abd-a05d-781d759c18b4",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'saveAsTextFile'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-746863c29585>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcount\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaveAsTextFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"output/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'int' object has no attribute 'saveAsTextFile'"
     ]
    }
   ],
   "source": [
    "count.saveAsTextFile(\"output/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eab4b9e-a192-4a1e-8c3b-5afa0573cff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.streaming import StreamingContext\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.functions import desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7fc472f-3383-4971-9d14-124969164ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext(master=\"spark://192.168.9.11:7077\", appName=\"maps_and_lazy_evaluation_example\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d303cfc-17a8-483f-a1b5-9d4b24bbdfe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ssc = StreamingContext(sc, 10 )\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d986a1ee-cf6d-4799-951c-0bf9682d0726",
   "metadata": {},
   "outputs": [],
   "source": [
    "socket_stream = ssc.socketTextStream(\"192.168.9.11\", 9999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac83d179-cdca-4384-a316-438a3561d4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = socket_stream.window( 20 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb2e1dc-46b5-4287-9607-6a50d2af3bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "fields = (\"tag\", \"count\" )\n",
    "Tweet = namedtuple( 'Tweet', fields )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed7ea2c-77f5-4aa0-96cf-85091d669ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Parenthesis for multiple lines or use \\.\n",
    "( lines.flatMap( lambda text: text.split( \" \" ) ) #Splits to a list\n",
    "  .filter( lambda word: word.lower().startswith(\"#\") ) # Checks for hashtag calls\n",
    "  .map( lambda word: ( word.lower(), 1 ) ) # Lower cases the word\n",
    "  .reduceByKey( lambda a, b: a + b ) # Reduces\n",
    "  .map( lambda rec: Tweet( rec[0], rec[1] ) ) # Stores in a Tweet Object\n",
    "  .foreachRDD( lambda rdd: rdd.toDF().sort( desc(\"count\") ) # Sorts Them in a DF\n",
    "  .limit(10).registerTempTable(\"tweets\") ) ) # Registers to a table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b2f6f5-f1e6-467a-9001-f81babb53ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ssc.start()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828a8068-3be6-4741-8443-0c2aac761911",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from IPython import display\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# Only works for Jupyter Notebooks!\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b003f922-3b28-485c-aadd-0270d171e74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "while count < 10:\n",
    "    \n",
    "    time.sleep( 3 )\n",
    "    top_10_tweets = sqlContext.sql( 'Select tag, count from tweets' )\n",
    "    top_10_df = top_10_tweets.toPandas()\n",
    "    display.clear_output(wait=True)\n",
    "    sns.plt.figure( figsize = ( 10, 8 ) )\n",
    "    sns.barplot( x=\"count\", y=\"tag\", data=top_10_df)\n",
    "    sns.plt.show()\n",
    "    count = count + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52028d54-afe1-438e-9a16-4c0e0668cf5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ssc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266e2054-bb29-4346-8b57-932052edcc69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.streaming import StreamingContext\n",
    "\n",
    "# Create a local StreamingContext with two working thread and batch interval of 1 second\n",
    "sc = SparkContext(master=\"spark://192.168.9.11:7077\", appName=\"maps_and_lazy_evaluation_example\")\n",
    "ssc = StreamingContext(sc, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1564db15-5599-493b-a9e9-1442e9f32b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = ssc.socketTextStream(\"192.168.9.11\", 9999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d7c7cb-1d33-45e6-a5eb-32d00a56d031",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = lines.flatMap(lambda line: line.split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b5e5b6-d2cf-40aa-a031-d4abf36b9028",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = words.map(lambda word: (word, 1))\n",
    "wordCounts = pairs.reduceByKey(lambda x, y: x + y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1402cc76-dc86-4141-8b55-e58400b8e2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordCounts.pprint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5070e7-836c-4673-b9ad-40ce80d31c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "ssc.start()             # Start the computation\n",
    "ssc.awaitTermination()  # Wait for the computation to terminate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d0fbf7-65ff-4d01-9793-9086c6cc04b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
